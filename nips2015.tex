\documentclass{article} % For LaTeX2e
\usepackage{nips15submit_e,times}
\usepackage{hyperref}
\usepackage{url}
\usepackage{amssymb}
\usepackage{booktabs}

%\documentstyle[nips14submit_09,times,art10]{article} % For LaTeX 2.09

\title{Accelerating Multimodal Sequence Retrieval with Convolutional Networks}


\author{
Colin Raffel
LabROSA
Columbia University
New York, NY 10027
\texttt{craffel@gmail.com}
\And
Daniel P.~W.~Ellis
LabROSA
Columbia University
New York, NY 10027
\texttt{dpwe@ee.columbia.edu}
}

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

%\nipsfinalcopy % Uncomment for camera-ready version

\begin{document}

\maketitle

\begin{abstract}
Given a large database of sequential data, a natural problem is to find the entry in the database which is most similar to a query sequence.
Warping-based similarity metrics such as the dynamic time warping (DTW) distance can be prohibitively expensive when the sequences are long and/or high-dimensional.
To mitigate these issues, \cite{raffel2015large} utilizes a convolutional network to map sequences of feature vectors to downsampled sequences of binary vectors.
On the task of matching synthetic renditions of pieces of music to a large database of audio recordings of songs, this approach was able to efficiently discard 99\% of the database with high confidence.
We extend this approach to the multimodal setting where rather than synthetic renditions a matrix representation of the piece's score is used instead, demonstrating that this approach is adaptable to the underlying representation.
\end{abstract}

\section{Introduction}
\label{sec:intro}

The ability to compute a similarity metric for sequences of feature vectors is necessary for the task of retrieving the most similar entry (nearest-neighbor search) in a database of sequences.
A natural way to compare sequences is to first find their optimal alignment and then compute the total distance between aligned feature vectors.
Aligning the sequences before computing the total distance makes metrics of this type robust to timing distortions (e.g.\ offset, skew, or cropping), and can be achieved in quadratic time using dynamic programming \cite{rakthanmanon2012searching}.
For feature vectors which are effectively compared with Euclidean distance (e.g.\ those with continuously-valued feature vectors), the most commonly used method of this type is dynamic time warping (DTW) \cite{sakoe1978dynamic}, which will be the focus of this work.

The quadratic cost of the dynamic programming-based alignment operation can make nearest-neighbor search infeasible for for databases with many entries and/or long sequences.
Furthermore, traditional DTW involves computing the pairwise distance between all feature vectors in the two sequences being compared, which can outweigh the cost of the alignment for high-dimensional data.
A common way to avoid these costs is to use ``pruning'' techniques, which use heuristics to skip a large portion of the database.
A wide variety of pruning methods have been proposed; in \cite{rakthanmanon2012searching} it is shown that their successful application can enable nearest-neighbor search in databases with trillions of sequences.
Despite their benefits, pruning methods typically rely on various constraints on the comparisons being made, such as the query sequence always being a subsequence of its correct match in the database or that the total number of aligned frames is fixed.
Furthermore, these methods suffer losses in efficiency when sequences are oversampled and/or high dimensional.

To avoid these issues, in \cite{raffel2015large} a learning-based method is proposed which utilizes a convolutional network to map sequences of feature vectors to downsampled sequences of binary vectors.
The resulting ``hash sequences'' can be much more efficiently compared using dynamic time warping, which enables flexible, problem-adaptive pruning.
In this paper, we will show that this framework is additionally flexible to multimodal settings, where the sequences being compared represent different types of data.

\section{Learning a More Efficient Representation for DTW}

\cite{raffel2015large}

\section{Shared Representations for Multimodal Sequences}

Piano roll matrices, 44.8 ms vs 22.2 s.

\subsection{MIDI to Audio Matching Experiment}

Re-cap of experiment

Results

\section{Extensions}

\bibliographystyle{unsrt}
\small
\bibliography{refs}

\end{document}
